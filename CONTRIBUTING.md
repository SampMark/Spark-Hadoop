# Contribui√ß√µes para o reposit√≥rio Spark-Hadoop

## üéØ Objetivos
- Fornecer um ambiente Docker reprodut√≠vel para clusters Hadoop + Spark + Jupyter.
- Manter scripts e configura√ß√µes organizados, com templates e valida√ß√µes.

Antes de abrir uma issue ou PR, verifique se o pedido est√° alinhado a este escopo.  

## üìã Reportar Bugs
1. Verifique se o erro j√° n√£o est√° registrado em [`issues`](https://github.com/SampMark/spark-hadoop/issues). 
2. Abra uma nova issue contendo:
   - **Resumo**: t√≠tulo curto e descritivo.  
   - **Descri√ß√£o**: passo a passo para reproduzir localmente.  
   - **Logs**: mensagens de erro de containers (`docker logs <container>`).  
   - **Ambiente**: vers√£o do Docker, Docker Compose, `.env` (omitindo senhas).

## ‚ú® Propor Features
1. Abra uma issue detalhando o caso de uso.  
2. Aguarde discuss√µes e alinhamentos com mantenedores.  
3. Ap√≥s aprova√ß√£o, fa√ßa fork e crie branch `feature/minha-feature`.
4. Garanta que:
   - Scripts Bash passem em `shellcheck`.  
   - Adicione testes de smoke em `tests/` se fizer altera√ß√µes que afetem sa√∫de do cluster.  
   - Atualize `README.md`, `CHANGELOG.md` e `docker-compose.template.yml` (se necess√°rio).

## üíª Submiss√£o de Pull Request
1. Crie branch no seu fork:
   ```bash
   git checkout -b feature/exemplo-feature

Siga estas diretrizes acima. Obrigado por querer colaborar! 
