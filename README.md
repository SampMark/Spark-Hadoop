# Spark e Hadoop Cluster Deployment

## 1. VisÃ£o Geral

O repositÃ³rio **Spark-Hadoop** Ã© projetado para provisionar, via Docker e Docker Compose, um cluster que combina o **Apache Spark** e **Apache Hadoop** e integraÃ§Ã£o com **JupyterLab**. Em suma, o repositÃ³rio fornece um ambiente **Docker** para um **cluster distribuÃ­do** que combina:

- **Apache Hadoop 3.4.x** (HDFS + YARN);
- **Apache Spark 3.3.x** (Spark Master, Spark Workers, Spark History Server);
- **JupyterLab** para notebooks interativos com kernels PySpark.

VocÃª terÃ¡, por padrÃ£o:
1. O nÃ³ **master** executa os seguintes serviÃ§os:
   - HDFS NameNode  
   - YARN ResourceManager  
   - Spark Master  
   - Spark History Server  
   - JupyterLab (se habilitado)

2. Os nÃ³s **workers** (replicados dinamicamente), executam:
   - HDFS DataNode  
   - YARN NodeManager  
   - Spark Worker  

O objetivo Ã© oferecer um ambiente â€œ_all-in-one_â€ para pesquisas e testes de Big Data, tornando simples os procedimentos de:

1. Implantar clusters Spark + Hadoop em _containers_ isolados;
2. Acessar a dashboards web (HDFS, YARN, Spark UI, JupyterLab) via mapeamento de portas;
3. Rodar jobs MapReduce e Spark, inclusive com notebooks interativos.

---

## ğŸ“‚ Estrutura de diretÃ³rios

Â´Â´Â´
spark-hadoop/
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .password
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ docker-compose.template.yml
â”œâ”€â”€ docker-compose.yml      â† gerado por init.sh
â”œâ”€â”€ LICENSE.apache          â† Apache 2.0 (Hadoop)
â”œâ”€â”€ LICENSE.mit             â† MIT (scripts e infra)
â”œâ”€â”€ pgsql
â”œâ”€â”€ README.md
â”œâ”€â”€ config_files/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ hadoop/
â”‚   â”‚   â”œâ”€â”€ core-site.xml.template
â”‚   â”‚   â”œâ”€â”€ hadoop-env.sh.template
â”‚   â”‚   â”œâ”€â”€ hdfs-site.xml.template
â”‚   â”‚   â”œâ”€â”€ mapred-site.xml.template
â”‚   â”‚   â”œâ”€â”€ yarn-env.sh.template
â”‚   â”‚   â””â”€â”€ yarn-site.xml.template
â”‚   â”œâ”€â”€ jupyterlab/
â”‚   â”‚   â”œâ”€â”€ overrides.json.template
â”‚   â”‚   â””â”€â”€ jupyter_notebook_config.py.template
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ spark-defaults.conf.template
â”‚   â”‚   â””â”€â”€ spark-env.sh.template
â”‚   â””â”€â”€ system/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ bash_common
â”‚       â””â”€â”€ ssh_config.template
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ entrypoint.sh
â”œâ”€â”€ myfiles/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ scripts/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_all.sh
â”‚   â”œâ”€â”€ init.sh
â”‚   â”œâ”€â”€ preflight_check.sh
â”‚   â”œâ”€â”€ bootstrap.sh
â”‚   â””â”€â”€ start_services.sh
â””â”€â”€ tests/
    â”œâ”€â”€ smoke_test_hadoop.sh
    â””â”€â”€ smoke_test_spark.sh
Â´Â´Â´
---

## ğŸš€ Quick Start

1. **Clone e entre na pasta**  
   ```bash
   git clone https://github.com/SampMark/hadoop_spark.git
   cd hadoop_spark


## :page_facing_up: License

`Apache Spark` e `Apache Hadoop` sÃ£o software livre e de cÃ³digo aberto, licenciados sob a [Apache License](https://github.com/cmdviegas/docker-hadoop-cluster/blob/master/LICENSE.apache) and are also free, open-source software.


Este script Ã© um software livre e de cÃ³digo aberto, licenciado sob [MIT License](https://github.com/cmdviegas/docker-hadoop-cluster/blob/master/LICENSE).

