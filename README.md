# ImplantaÃ§Ã£o de clusters Spark-Hadoop (_Cluster Deployment_) com ambiente Docker

## 1. VisÃ£o Geral

Bem-vindo ao repositÃ³rio **Spark-Hadoop**! Este projeto foi cuidadosamente construÃ­do para provisionar, de forma simples e rÃ¡pida, um cluster completo que combina o poder do Apache Spark e do Apache Hadoop, via Docker, um cluster que combina o **Apache Spark** e **Apache Hadoop**, com integraÃ§Ã£o ao **JupyterLab**. 

O objetivo Ã© oferecer um ambiente â€œ_all-in-one_â€, isolado e pronto para uso, que abstrai a complexidade da configuraÃ§Ã£o manual.  Ã‰ a ferramenta interessante para estudantes, desenvolvedores e engenheiros de dados, no desenvolvimento e testes de aplicaÃ§Ãµes em Big Data, tornando simples os procedimentos de:

1. *Implantar clusters funcionais* de Spark e Hadoop em contÃªineres Docker isolados;
2. *Aprendizado na prÃ¡tica*, acessando _dashboards web_ de todos os serviÃ§os (HDFS, YARN, Spark UI, JupyterLab) para entender como as peÃ§as se conectam;
3. *Executar jobs de Big Data*, tanto no modelo clÃ¡ssico MapReduce do Hadoop quanto com o processamento em memÃ³ria de alta performance do Spark.

### **1.1. Arquitetura do Cluster**
O ambiente Docker provisiona um cluster distribuÃ­do que combina:

- **Apache Hadoop 3.4.x**, fornece o HDFS (_Hadoop Distributed File System_) para armazenamento de dados massivos e tolerante a falhas, e o YARN (_Yet Another Resource Negotiator_) para um gerenciamento robusto dos recursos computacionais (CPU e memÃ³ria) do(s) cluster(s).
- **Apache Spark 4.0.x**, atua como o motor de processamento de dados em larga escala, executando tarefas sobre o YARN e lendo/escrevendo dados no HDFS.
- **JupyterLab**, oferece um ambiente de notebook interativo, prÃ©-configurado com um kernel `PySpark`, permitindo a anÃ¡lise de dados e o desenvolvimento de forma Ã¡gil e visual.

A **arquitetura padrÃ£o** Ã© composta por:
- 1 **NÃ³ Mestre** (`master`), orquestra o cluster, executando os serviÃ§os de gerenciamento:
   - **HDFS NameNode**, Ã© "cÃ©rebro" do HDFS, gerencia os metadados do sistema de arquivos.
   - **YARN ResourceManager**, Ã© o "chefe" do YARN, aloca recursos para as aplicaÃ§Ãµes.
   - **Spark History Server**, Ã© uma UI web para visualizar o histÃ³rico de aplicaÃ§Ãµes Spark concluÃ­das.
   - **JupyterLab**, servidor que fornece a interface de notebooks.

- `N` **NÃ³s de Trabalho** (`workers`), sÃ£o os "operÃ¡rios" do cluster que podem ser replicados dinamicamente, executando as tarefas de armazenamento e processamento:
   - **HDFS DataNode**, armazena os blocos de dados reais.  
   - **YARN NodeManager**, gerencia os recursos de uma mÃ¡quina individual e executa as tarefas.
   - "Spark Worker", o nÃºmero de `workers` Ã© facilmente configurÃ¡vel em arquivo `.env`.

---

## 2. PrÃ©-requisitos
Antes de comeÃ§ar, certifique-se dos seguintes requisitos, softwares instalados e funcionando em sua mÃ¡quina:

- **Sistema Operacional**, preferencialmente, uma distribuiÃ§Ã£o Linux (como Ubuntu ou CentOS).
- **Java Development Kit (JDK)**, o Hadoop e o Spark rodam na JVM. Ã‰ crucial instalar uma versÃ£o compatÃ­vel (ex: JDK 11 para Hadoop 3.x). A variÃ¡vel de ambiente `JAVA_HOME` deve ser configurada e apontar para o diretÃ³rio de instalaÃ§Ã£o do Java.
- **SSH (Secure Shell)**, essencial para que o nÃ³ mestre possa se comunicar e gerenciar os nÃ³s de trabalho sem a necessidade de senhas a cada comando. Isso Ã© feito gerando um par de chaves SSH (`ssh-keygen`) e copiando a chave pÃºblica para o arquivo `authorized_keys` em todos os nÃ³s (inclusive no prÃ³prio mestre).
- **Docker Engine** na versÃ£o 20.10.0 ou superior.
- **Docker Compose** na versÃ£o V2 (`docker compose`), Ã© fortemente recomendada.
- **Recursos mÃ­nimos** de pelo menos 8 GB de RAM alocados para o Docker, para uma experiÃªncia fluida com 2 workers.
- **Portas Livres**, verifique se as portas padrÃ£o (ex: 8088, 9870, 8888, 18080) nÃ£o estÃ£o em uso por outras aplicaÃ§Ãµes.

---

## 3. âœ¨InÃ­cio RÃ¡pido
Siga estes passos para colocar seu cluster no ar em poucos minutos.

**Passo 1: Clonar o RepositÃ³rio**
Abra seu terminal e clone este repositÃ³rio para sua mÃ¡quina local.
```
git clone https://github.com/SampMark/Spark-Hadoop.git
cd spark_hadoop
```
**Passo 2: Construir e Iniciar o Cluster**
Com o Docker em execuÃ§Ã£o, execute o seguinte comando na raiz do projeto para construir as imagens e iniciar todos os serviÃ§os em background:
```
docker compose up -d --build
```
   * `up`: Cria e inicia os contÃªineres.
   * `-d`: Modo "detached" (os contÃªineres rodam em background).
   * `--build`: ForÃ§a a construÃ§Ã£o da imagem Docker na primeira vez ou se o Dockerfile for alterado.

O primeiro inÃ­cio pode demorar alguns minutos, pois o Docker irÃ¡ baixar as imagens base e as distribuiÃ§Ãµes do Hadoop e Spark. ApÃ³s a conclusÃ£o, seu cluster estarÃ¡ pronto para uso!

---

## 4. CustomizaÃ§Ã£o do Ambiente (arquivo `.env`)
A principal forma de customizar o cluster (nÃºmero de workers, versÃµes, alocaÃ§Ã£o de memÃ³ria, etc.) Ã© atravÃ©s do arquivo .env. Isso evita a necessidade de editar manualmente os arquivos XML ou scripts.

Abaixo estÃ£o as variÃ¡veis mais importantes que vocÃª pode ajustar:

| VariÃ¡vel                      | PadrÃ£o (.env)   | DescriÃ§Ã£o                                                                 |
| :---------------------------- | :-------------: | :------------------------------------------------------------------------ |
| `SPARK_WORKER_INSTANCES`      | `2`             | NÃºmero de nÃ³s workers (DataNodes/NodeManagers) a serem criados no cluster |
| `HADOOP_VERSION`              | `3.4.0`         | VersÃ£o do Apache Hadoop a ser utilizada                                   |
| `SPARK_VERSION`               | `3.3.4`         | VersÃ£o do Apache Spark a ser utilizada                                    |
| `HDFS_REPLICATION_FACTOR`     | `2`             | Fator de replicaÃ§Ã£o padrÃ£o do HDFS (`dfs.replication`). Deve ser â‰¤ nÃºmero de workers |
| `YARN_NODEMANAGER_MEMORY_MB`  | `4096`          | MemÃ³ria total (MB) que cada NodeManager pode alocar para contÃªineres (`yarn.nodemanager.resource.memory-mb`) |
| `SPARK_DRIVER_MEMORY`         | `1g`            | MemÃ³ria padrÃ£o para o Driver do Spark (`spark.driver.memory`)             |
| `SPARK_EXECUTOR_MEMORY`       | `1536m`         | MemÃ³ria padrÃ£o por Executor do Spark (`spark.executor.memory`)            |
| `SPARK_EXECUTOR_CORES`        | `2`             | NÃºmero de vCores por Executor do Spark (`spark.executor.cores`)           |
| `JUPYTERLAB_PORT`             | `8888`          | Porta local mapeada para a interface do JupyterLab                        |
| `SPARK_HISTORY_UI_PORT`       | `18080`         | Porta local mapeada para a UI do Spark History Server                     |

**Importante**: caso altere o `.env`, pode ser necessÃ¡rio recriar os contÃªineres para que as mudanÃ§as tenham efeito: 
```
docker compose down && docker compose up -d
```
---

## 5. Acessando os ServiÃ§os e UIs Web
ApÃ³s iniciar o cluster, o usuÃ¡rio pode acessar as interfaces web dos diferentes serviÃ§os atravÃ©s do navegador.

| ServiÃ§o              | Porta (Local) | URL de Acesso          | DescriÃ§Ã£o |
| :------------------- | :-----------: | :--------------------: |-------------------------------------------------- |
| HDFS NameNode        | 9870          | http://localhost:9870  | UI para monitorar o estado do HDFS.               |
| YARN ResourceManager | 8088          | http://localhost:8088  | UI para monitorar o cluster, filas e aplicaÃ§Ãµes.  |
| Spark History Server | 18080         | http://localhost:18080 | UI para visualizar o histÃ³rico de aplicaÃ§Ãµes Spark. |
| JupyterLab           | 8888          | http://localhost:8888  | Ambiente interativo para notebooks PySpark.       |

---

## 6. Exemplos prÃ¡ticos de uso
O usuÃ¡rio pode interagir com o cluster executando comandos dentro do contÃªiner master ou submetendo jobs.

#### 6.1. Interagindo com HDFS
Execute comandos HDFS a partir do contÃªiner `spark-master`:
```
# Listar o conteÃºdo do diretÃ³rio raiz do HDFS
docker compose exec spark-master hdfs dfs -ls /

# Criar um novo diretÃ³rio
docker compose exec spark-master hdfs dfs -mkdir /meu-diretorio-teste

# Copiar um arquivo local (do README.md) para o HDFS
docker compose exec spark-master hdfs dfs -put README.md /meu-diretorio-teste
```
#### 6.2. Submetendo um Job Spark (SparkPi)
Execute o exemplo `SparkPi` para calcular o valor de Pi. Este job serÃ¡ submetido ao YARN.

```
docker compose exec spark-master spark-submit \
  --class org.apache.spark.examples.SparkPi \
  --master yarn \
  --deploy-mode client \
  --num-executors 2 \
  --executor-memory 512m \
  $SPARK_HOME/examples/jars/spark-examples_*.jar 100
```
ApÃ³s a execuÃ§Ã£o, o usuÃ¡rio verÃ¡ o job concluÃ­do na UI do YARN (http://localhost:8088) e na UI do Spark History Server (http://localhost:18080).

---

## 7. Gerenciando o Cluster
Use os seguintes comandos `docker compose para gerenciar o ciclo de vida do seu cluster.

* **Iniciar o cluster em background:**
```
docker compose up -d
```

* **Parar e remover os contÃªineres:**
```
docker compose down
```

* **Verificar o status dos contÃªineres:**
```
docker compose ps
```

* **Visualizar os logs de um serviÃ§o (ex: master):**
```
docker compose logs -f spark-master
```
---

## 8. ğŸ”—ReferÃªncias e DocumentaÃ§Ã£o Oficial
Para um entendimento mais profundo dos componentes, consulte a documentaÃ§Ã£o oficial:

* ZAHARIA, Matei _et al_. **Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing**. In: USENIX Symposium on Networked Systems Design and Implementation (NSDI), 9., 2012, San Jose, CA. Anais. Berkeley: USENIX Association, 2012. p. 1-14. DisponÃ­vel em: [https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf) Acesso em: 01 Jun. 2025.

* MCDONALD, Carol. **Introduction to Spark Processing**. In: MCDONALD, Carol. ACCELERATING APACHE SPARK 3: Leveraging NVIDIA GPUs to Power the Next Era of Analytics and Al. [S.l.]: NVIDIA, 2021. cap. 1, p. 12-30. DisponÃ­vel em: [https://images.nvidia.com/aem-dam/Solutions/deep-learning/deep-learning-ai/solutions/Accelerating-Apache-Spark-3-08262021.pdf](https://images.nvidia.com/aem-dam/Solutions/deep-learning/deep-learning-ai/solutions/Accelerating-Apache-Spark-3-08262021.pdf) Acesso em: 03 Jun. 2025.

* [DocumentaÃ§Ã£o do Apache Hadoop 3.x](https://hadoop.apache.org/docs/stable/)
* [DocumentaÃ§Ã£o do Apache Spark 3.3.x](https://spark.apache.org/docs/3.3.4/)
* [DocumentaÃ§Ã£o do Docker](https://docs.docker.com/)
* [DocumentaÃ§Ã£o do Docker Compose](https://docs.docker.com/compose/)
* [RepositÃ³rio GitHub `haddop-spark` Prof. Carlos M. D. Viegas](https://github.com/cmdviegas/hadoop-spark)

---

## ğŸ“‚ 9. Estrutura de diretÃ³rios e arquivos

```
spark-hadoop/
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env                            â† Arquivo principal para customizaÃ§Ã£o do cluster.
â”œâ”€â”€ .env.template
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .password
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ docker-compose.template.yml     â† Define os serviÃ§os (master, workers) e redes do Docker.
â”œâ”€â”€ docker-compose.yml              â† gerado por init.sh
â”œâ”€â”€ LICENSE.apache                  â† Apache 2.0 (Hadoop)
â”œâ”€â”€ LICENSE.mit                     â† MIT (scripts e infra)
â”œâ”€â”€ pgsql
â”œâ”€â”€ README.md
â”œâ”€â”€ config_files/                   â† ContÃ©m os TEMPLATES de configuraÃ§Ã£o.
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ hadoop/                     â† Templates para .xml.
â”‚   â”‚   â”œâ”€â”€ core-site.xml.template
â”‚   â”‚   â”œâ”€â”€ hadoop-env.sh.template
â”‚   â”‚   â”œâ”€â”€ hdfs-site.xml.template
â”‚   â”‚   â”œâ”€â”€ mapred-site.xml.template
â”‚   â”‚   â”œâ”€â”€ yarn-env.sh.template
â”‚   â”‚   â””â”€â”€ yarn-site.xml.template
â”‚   â”œâ”€â”€ jupyterlab/
â”‚   â”‚   â”œâ”€â”€ overrides.json.template
â”‚   â”‚   â””â”€â”€ jupyter_notebook_config.py.template
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ spark-defaults.conf.template
â”‚   â”‚   â””â”€â”€ spark-env.sh.template
â”‚   â””â”€â”€ system/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ bash_common
â”‚       â””â”€â”€ ssh_config.template
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ entrypoint.sh
â”œâ”€â”€ myfiles/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ data/                    â† Coloque seus datasets aqui.
â”‚   â”œâ”€â”€ notebooks/               â† Crie seus notebooks Jupyter aqui.
â”‚   â””â”€â”€ scripts/                 â† Guarde seus scripts Python/Scala aqui.
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_all.sh
â”‚   â”œâ”€â”€ init.sh
â”‚   â”œâ”€â”€ preflight_check.sh
â”‚   â”œâ”€â”€ bootstrap.sh             â† Script interno que cuida da formataÃ§Ã£o do HDFS e da inicializaÃ§Ã£o dos serviÃ§os.
â”‚   â””â”€â”€ start_services.sh
â””â”€â”€ tests/
    â”œâ”€â”€ smoke_test_hadoop.sh
    â””â”€â”€ smoke_test_spark.sh
```
---

## 10. LicenÃ§as

- `Apache Spark` e `Apache Hadoop` sÃ£o software livre e de cÃ³digo aberto, licenciados sob a [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).

- Este script Ã© um software livre e de cÃ³digo aberto, licenciado sob [MIT License](https://opensource.org/license/mit).

