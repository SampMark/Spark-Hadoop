# =============================================================================
# Dockerfile para Cluster Hadoop e Spark (VERS√ÉO REVISADA)
#
# Autor: Marcus V D Sampaio/Organiza√ß√£o: IFRN - Baseado no script de Carlos M D Viegas
# Vers√£o: 1.2 (Revisado com base nas melhores pr√°ticas)
# Data: 2025-06-11
#
# Descri√ß√£o:
#   Este Dockerfile cria uma imagem Docker contendo um ambiente completo com
#   Apache Hadoop e Apache Spark, baseado em Ubuntu 24.04. A imagem √© projetada
#   para ser flex√≠vel e configur√°vel em tempo de execu√ß√£o.
#
# Como Funciona (Fluxo de Trabalho Revisado):
#   1. Pr√©-requisito: O usu√°rio executa um script 'init.sh' que baixa os
#      arquivos .tar.gz do Hadoop e Spark, e seus respectivos arquivos .sha512,
#      para o contexto de build.
#   2. Build Multi-Stage:
#      - Est√°gios 'build-hadoop' e 'build-spark': Copiam os arquivos .tar.gz e
#        .sha512. VALIDAM a integridade dos arquivos e os extraem.
#        O build FALHAR√Å se os arquivos n√£o existirem ou se o checksum for inv√°lido.
#      - Est√°gio 'final': Constr√≥i a imagem final combinando os bin√°rios preparados
#        com as depend√™ncias do sistema e configura√ß√µes.
# =============================================================================

# =============================================================================
# EST√ÅGIO 1: Prepara√ß√£o e Valida√ß√£o do Hadoop
# =============================================================================
FROM ubuntu:24.04 AS build-hadoop

SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Argumento de build para a vers√£o do Hadoop
ARG HADOOP_VERSION=3.4.1

# Vari√°veis de ambiente para o est√°gio
ENV MY_USERNAME=myuser
ENV MY_WORKDIR=/home/${MY_USERNAME}
ENV HADOOP_VERSION=${HADOOP_VERSION}
ENV HADOOP_HOME=${MY_WORKDIR}/hadoop
ENV HADOOP_TARBALL="hadoop-${HADOOP_VERSION}.tar.gz"

WORKDIR ${MY_WORKDIR}

# Copia o tarball e o checksum do contexto de build.
# O Dockerfile agora DEPENDE que esses arquivos tenham sido pr√©-baixados.
COPY hadoop-*.tar.gz hadoop-*.tar.gz.sha512 ./

# Valida, verifica o checksum e extrai. Remove a l√≥gica de 'wget'.
RUN \
    # 1. Verifica se os arquivos necess√°rios existem
    if [ ! -f "${HADOOP_TARBALL}" ] || [ ! -f "${HADOOP_TARBALL}.sha512" ]; then \
      echo "üö® ERRO DE BUILD üö®: Arquivo ${HADOOP_TARBALL} e/ou seu checksum .sha512 n√£o encontrado." && \
      echo "‚ö†Ô∏è Execute o script de inicializa√ß√£o para baixar as depend√™ncias primeiro. ‚ö†Ô∏è" && \
      exit 1; \
    fi && \
    # 2. Valida a integridade do arquivo usando o checksum
    echo "Verificando checksum do Hadoop..." && \
    sha512sum -c "${HADOOP_TARBALL}.sha512" && \
    # 3. Extrai o Hadoop
    echo "Extraindo Hadoop..." && \
    tar -zxf "${HADOOP_TARBALL}" -C ${MY_WORKDIR} && \
    # 4. Limpeza
    rm -f "${HADOOP_TARBALL}" "${HADOOP_TARBALL}.sha512" && \
    # 5. Renomeia para um nome gen√©rico
    mv "${MY_WORKDIR}/hadoop-${HADOOP_VERSION}" "${HADOOP_HOME}"

# =============================================================================
# EST√ÅGIO 2: Prepara√ß√£o e Valida√ß√£o do Spark
# =============================================================================
FROM ubuntu:24.04 AS build-spark

SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Argumentos de build para a vers√£o do Spark
ARG SPARK_VERSION=3.5.6
ARG SPARK_PROFILE=hadoop3

# Vari√°veis de ambiente para o est√°gio
ENV MY_USERNAME=myuser
ENV MY_WORKDIR=/home/${MY_USERNAME}
ENV SPARK_VERSION=${SPARK_VERSION}
ENV SPARK_HOME=${MY_WORKDIR}/spark
ENV SPARK_TARBALL="spark-${SPARK_VERSION}-bin-${SPARK_PROFILE}.tgz"

WORKDIR ${MY_WORKDIR}

# Copia o tarball e o checksum do contexto.
COPY spark-*.tgz spark-*.tgz.sha512 ./

# Valida, verifica o checksum e extrai.
RUN \
    # 1. Verifica se os arquivos necess√°rios existem
    if [ ! -f "${SPARK_TARBALL}" ] || [ ! -f "${SPARK_TARBALL}.sha512" ]; then \
      echo "üö® ERRO DE BUILD üö®: Arquivo ${SPARK_TARBALL} e/ou seu checksum .sha512 n√£o encontrado." && \
      echo "‚ö†Ô∏è Execute o script de inicializa√ß√£o para baixar as depend√™ncias primeiro. ‚ö†Ô∏è" && \
      exit 1; \
    fi && \
    # 2. Valida a integridade do arquivo
    echo "Verificando checksum do Spark..." && \
    sha512sum -c "${SPARK_TARBALL}.sha512" && \
    # 3. Extrai o Spark
    echo "Extraindo Spark..." && \
    tar -zxf "${SPARK_TARBALL}" -C ${MY_WORKDIR} && \
    # 4. Limpeza
    rm -f "${SPARK_TARBALL}" "${SPARK_TARBALL}.sha512" && \
    # 5. Renomeia para um nome gen√©rico
    mv "${MY_WORKDIR}/spark-${SPARK_VERSION}-bin-${SPARK_PROFILE}" "${SPARK_HOME}"

# =============================================================================
# EST√ÅGIO 3: Imagem Final
# =============================================================================
FROM ubuntu:24.04 AS final

LABEL maintainer="Marcus V D Sampaio <prof.marcus.sampaio@gmail.com>"
LABEL description="Imagem Docker com Apache Hadoop, Apache Spark e JupyterLab para clusters de Big Data."

SHELL ["/bin/bash", "-o", "pipefail", "-c"]

ARG HADOOP_VERSION
ARG SPARK_VERSION
ARG APT_MIRROR

ENV MY_USERNAME=myuser
ENV MY_GROUP=myuser
ENV MY_WORKDIR=/home/${MY_USERNAME}
ENV HADOOP_VERSION=${HADOOP_VERSION}
ENV SPARK_VERSION=${SPARK_VERSION}
ENV HADOOP_HOME=${MY_WORKDIR}/hadoop
ENV SPARK_HOME=${MY_WORKDIR}/spark
ENV HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
ENV SPARK_CONF_DIR=${SPARK_HOME}/conf
ENV PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:${SPARK_HOME}/bin:${SPARK_HOME}/sbin:${PATH}
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV DEBIAN_FRONTEND=noninteractive

RUN \
    # <<< CORRE√á√ÉO >>>: L√≥gica de APT_MIRROR mantida, mas ciente das limita√ß√µes com o novo formato de sources.
    if [ -n "$APT_MIRROR" ]; then \
      sed -i "s|http://archive.ubuntu.com/ubuntu|${APT_MIRROR}|g" /etc/apt/sources.list.d/ubuntu.sources; \
    fi && \
    apt-get update -qq && \
    apt-get install -y --no-install-recommends \
      openjdk-11-jdk-headless \
      ssh \
      sudo \
      python3.12 \
      python3-pip \
      nano \
      dos2unix \
      wget \
      curl \
      iputils-ping \
      gosu \
    && \
    apt-get autoremove -yqq --purge && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    ln -sf /usr/bin/python3.12 /usr/bin/python && \
    ln -sf /usr/bin/python3.12 /usr/bin/python3

# Instala depend√™ncias necess√°rias para o projeto
COPY ./requirements.txt /tmp/requirements.txt

RUN \
    pip install --no-cache-dir --break-system-packages -q -r /tmp/requirements.txt && \
    rm /tmp/requirements.txt

RUN \
    userdel --remove ubuntu || true && \
    groupadd --gid 1000 ${MY_GROUP} || true && \
    useradd --uid 1000 --gid ${MY_GROUP} --shell /bin/bash --create-home ${MY_USERNAME} && \
    usermod -aG sudo ${MY_USERNAME} && \
    echo "${MY_USERNAME} ALL=(ALL) NOPASSWD: ALL" > /etc/sudoers.d/${MY_USERNAME}

WORKDIR ${MY_WORKDIR}

# Consolida as instru√ß√µes COPY para reduzir camadas.
# Copia bin√°rios preparados e depois todos os arquivos da aplica√ß√£o.
COPY --from=build-hadoop --chown=${MY_USERNAME}:${MY_GROUP} ${HADOOP_HOME} ${HADOOP_HOME}/
COPY --from=build-spark --chown=${MY_USERNAME}:${MY_GROUP} ${SPARK_HOME} ${SPARK_HOME}/
COPY --chown=${MY_USERNAME}:${MY_GROUP} . ${MY_WORKDIR}/

USER ${MY_USERNAME}
RUN \
    dos2unix -q -k ${MY_WORKDIR}/scripts/*.sh ${MY_WORKDIR}/docker/entrypoint.sh && \
    echo -e '\n# Carrega configura√ß√µes comuns do cluster\n[ -f "${HOME}/.bash_common" ] && . "${HOME}/.bash_common"\n' >> "${MY_WORKDIR}/.bashrc" && \
    ssh-keygen -q -t rsa -N "" -f ${MY_WORKDIR}/.ssh/id_rsa && \
    cat ${MY_WORKDIR}/.ssh/id_rsa.pub >> ${MY_WORKDIR}/.ssh/authorized_keys && \
    # Adicionado .ssh/config √† configura√ß√£o de permiss√µes
    chmod 0700 ${MY_WORKDIR}/.ssh && \
    chmod 0600 ${MY_WORKDIR}/.ssh/authorized_keys ${MY_WORKDIR}/.ssh/id_rsa && \
    chmod 0644 ${MY_WORKDIR}/.ssh/id_rsa.pub && \
    # Cria diret√≥rio de log para o metastore do Spark SQL.
    mkdir -p ${MY_WORKDIR}/derby-metastore

# Configura o entrypoint e o comando padr√£o
ENTRYPOINT ["/home/myuser/docker/entrypoint.sh"]
CMD ["bash", "/home/myuser/scripts/bootstrap.sh", "MASTER"]