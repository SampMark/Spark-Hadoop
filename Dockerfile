# =============================================================================
# Dockerfile para Cluster Hadoop e Spark
#
# Autor: Marcus V D Sampaio/Organiza√ß√£o: IFRN - Baseado no script de Carlos M D Viegas
# Vers√£o: 1.1
# Data: 2024-05-07
#
# Descri√ß√£o:
#   Este Dockerfile cria uma imagem Docker contendo um ambiente completo com
#   Apache Hadoop e Apache Spark, baseado em Ubuntu 24.04. A imagem √© projetada
#   para ser flex√≠vel e configur√°vel em tempo de execu√ß√£o.
#
# Como Funciona (Fluxo de Trabalho):
#   1. Pr√©-requisito: O usu√°rio executa um script inicial (ex: `init.sh` via
#      `docker compose run --rm init`) que baixa os arquivos .tar.gz do Hadoop
#      e Spark para o contexto de build do Docker.
#   2. Build Multi-Stage:
#      - Est√°gios 'build-hadoop' e 'build-spark': Estes est√°gios copiam os
#        arquivos .tar.gz pr√©-baixados e os extraem. Isso isola a prepara√ß√£o
#        dos bin√°rios.
#      - Est√°gio 'final': Este √© o est√°gio principal que constr√≥i a imagem final.
#        - Instala todas as depend√™ncias do sistema (Java, Python, SSH, etc.).
#        - Instala as bibliotecas Python necess√°rias.
#        - Cria um usu√°rio n√£o-privilegiado ('myuser') para executar os servi√ßos.
#        - Copia os bin√°rios extra√≠dos de Hadoop e Spark dos est√°gios anteriores.
#        - Copia todos os scripts (.sh), templates de configura√ß√£o (.template)
#          e outros arquivos necess√°rios para dentro da imagem.
#        - Realiza a configura√ß√£o final do ambiente do usu√°rio (ex: chaves SSH).
#   3. Entrypoint: O ponto de entrada da imagem √© definido como o script `entrypoint.sh`.
#      Este script √© executado quando um cont√™iner √© iniciado, e √© respons√°vel por:
#      - Gerar os arquivos de configura√ß√£o finais a partir dos templates.
#      - Definir permiss√µes.
#      - Entregar a execu√ß√£o para o script principal (bootstrap.sh).
#
# =============================================================================


# =============================================================================
# EST√ÅGIO 1: Prepara√ß√£o do Hadoop
# Este est√°gio espera que o arquivo hadoop-*.tar.gz, caso j√° tenha sido baixado
# para o contexto de build pelo script `init.sh`.
# =============================================================================
FROM ubuntu:24.04 AS build-hadoop

# Usar bash com pipefail para capturar erros em pipelines
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Argumento de build para a vers√£o do Hadoop, passado via docker-compose
ARG HADOOP_VERSION

# Vari√°veis de ambiente para o est√°gio
ENV MY_USERNAME=myuser
ENV MY_WORKDIR=/home/${MY_USERNAME}
ENV HADOOP_VERSION=${HADOOP_VERSION}
ENV HADOOP_HOME=${MY_WORKDIR}/hadoop

WORKDIR ${MY_WORKDIR}

# Copia o tarball do Hadoop para o diret√≥rio de trabalho do est√°gio
COPY hadoop-*.tar.gz ${MY_WORKDIR}/

# Valida a exist√™ncia do arquivo e o extrai
RUN \
    # Verifica se o tarball do Hadoop existe
    if [ ! -f "${MY_WORKDIR}/hadoop-${HADOOP_VERSION}.tar.gz" ]; then \
        echo "üö® ERRO DE BUILD üö®: Arquivo hadoop-${HADOOP_VERSION}.tar.gz n√£o encontrado." && \
        echo "‚ö†Ô∏è Execute 'docker compose run --rm init' primeiro para baixar as depend√™ncias. ‚ö†Ô∏è" && \
        exit 1; \
    fi && \
    # Extrai o Hadoop para o sistema de arquivos do cont√™iner
    tar -zxf "hadoop-${HADOOP_VERSION}.tar.gz" -C ${MY_WORKDIR} && \
    # Remove o tarball para economizar espa√ßo
    rm -f "hadoop-${HADOOP_VERSION}.tar.gz" && \
    # Renomeia o diret√≥rio extra√≠do para um nome gen√©rico 'hadoop' para facilitar o acesso
    mv "${MY_WORKDIR}/hadoop-${HADOOP_VERSION}" "${HADOOP_HOME}"


# =============================================================================
# EST√ÅGIO 2: Prepara√ß√£o do Spark
# Similar ao est√°gio do Hadoop, espera um tarball do Spark pr√©-baixado.
# =============================================================================
FROM ubuntu:24.04 AS build-spark

# Usar bash com pipefail
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Argumento de build para a vers√£o do Spark
ARG SPARK_VERSION

# Vari√°veis de ambiente para o est√°gio
ENV MY_USERNAME=myuser
ENV MY_WORKDIR=/home/${MY_USERNAME}
ENV SPARK_VERSION=${SPARK_VERSION}
ENV SPARK_HOME=${MY_WORKDIR}/spark

WORKDIR ${MY_WORKDIR}

# Copia o tarball do Spark
COPY spark-*.tgz ${MY_WORKDIR}/

# Valida a exist√™ncia do arquivo e o extrai
RUN \
    # Verifica se o tarball do Spark existe
    if [ ! -f "${MY_WORKDIR}/spark-${SPARK_VERSION}-bin-hadoop3.tgz" ]; then \
        echo "üö® ERRO DE BUILD üö®: Arquivo spark-${SPARK_VERSION}-bin-hadoop3.tgz n√£o encontrado." && \
        echo "‚ö†Ô∏è Execute 'docker compose run --rm init' primeiro para baixar as depend√™ncias. ‚ö†Ô∏è" && \
        exit 1; \
    fi && \
    # Extrai o Spark
    tar -zxf "spark-${SPARK_VERSION}-bin-hadoop3.tgz" -C ${MY_WORKDIR} && \
    # Remove o tarball
    rm -f "spark-${SPARK_VERSION}-bin-hadoop3.tgz" && \
    # Renomeia o diret√≥rio extra√≠do para 'spark'
    mv "${MY_WORKDIR}/spark-${SPARK_VERSION}-bin-hadoop3" "${SPARK_HOME}"


# =============================================================================
# EST√ÅGIO 3: Imagem Final
# Constr√≥i a imagem final combinando os resultados dos est√°gios anteriores
# com as depend√™ncias do sistema e configura√ß√µes.
# =============================================================================
FROM ubuntu:24.04 AS final

LABEL maintainer="Marcus V D Sampaio <prof.marcus.sampaio@gmail.com>"
LABEL description="Imagem Docker com Apache Hadoop, Apache Spark e JupyterLab para clusters de Big Data."

# Usar bash com pipefail
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Argumentos de build passados pelo docker-compose
ARG HADOOP_VERSION
ARG SPARK_VERSION
ARG APT_MIRROR

# --- Vari√°veis de Ambiente Globais ---
# Definidas para serem usadas pelos scripts e aplica√ß√µes dentro do cont√™iner.
ENV MY_USERNAME=myuser
ENV MY_GROUP=myuser
ENV MY_WORKDIR=/home/${MY_USERNAME}
ENV HADOOP_VERSION=${HADOOP_VERSION}
ENV SPARK_VERSION=${SPARK_VERSION}
ENV HADOOP_HOME=${MY_WORKDIR}/hadoop
ENV SPARK_HOME=${MY_WORKDIR}/spark
ENV HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
ENV SPARK_CONF_DIR=${SPARK_HOME}/conf
ENV PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:${SPARK_HOME}/bin:${SPARK_HOME}/sbin:${PATH}
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV DEBIAN_FRONTEND=noninteractive
ENV APT_MIRROR="${APT_MIRROR:-http://archive.ubuntu.com/ubuntu}"

# --- Instala√ß√£o de Depend√™ncias do Sistema ---
RUN \
    # Opcional: Altera o espelho do APT se um for fornecido, pode acelerar o build em algumas regi√µes
    sed -i "s|http://archive.ubuntu.com/ubuntu|${APT_MIRROR}|g" /etc/apt/sources.list.d/ubuntu.sources && \
    # Atualiza a lista de pacotes e instala as depend√™ncias em uma √∫nica camada para otimizar o tamanho
    apt-get update -qq && \
    apt-get install -y --no-install-recommends \
        # Essenciais para Hadoop/Spark
        openjdk-11-jdk-headless \
        ssh \
        sudo \
        # Essenciais para Python/Jupyter
        python3.12 \
        python3-pip \
        # Utilit√°rios gerais
        nano \
        dos2unix \
        wget \
        curl \
        iputils-ping \
        gosu \
    && \
    # --- Limpeza do Cache do APT ---
    # Remove caches e listas para reduzir o tamanho final da imagem
    apt-get autoremove -yqq --purge && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    # --- Cria√ß√£o de Links Simb√≥licos para Python ---
    # Garante que `python` e `python3` apontem para a vers√£o instalada
    ln -sf /usr/bin/python3.12 /usr/bin/python && \
    ln -sf /usr/bin/python3.12 /usr/bin/python3

# --- Instala√ß√£o de Depend√™ncias Python ---
# Copia o arquivo de requisitos primeiro para aproveitar o cache do Docker.
# O build s√≥ re-executar√° este passo se o requirements.txt mudar.
COPY requirements.txt /tmp/requirements.txt
RUN \
    pip install --no-cache-dir --break-system-packages -q -r /tmp/requirements.txt && \
    rm /tmp/requirements.txt

# --- Cria√ß√£o do Usu√°rio e Grupos ---
RUN \
    # Remove o usu√°rio padr√£o 'ubuntu', se existir
    userdel --remove ubuntu || true && \
    # Cria o grupo e o usu√°rio da aplica√ß√£o ('myuser' por padr√£o)
    groupadd --gid 1000 ${MY_GROUP} || true && \
    useradd --uid 1000 --gid ${MY_GROUP} --shell /bin/bash --create-home ${MY_USERNAME} && \
    # Adiciona o usu√°rio ao grupo sudo e concede permiss√µes sudo sem senha
    usermod -aG sudo ${MY_USERNAME} && \
    echo "${MY_USERNAME} ALL=(ALL) NOPASSWD: ALL" > /etc/sudoers.d/${MY_USERNAME}

# Define o diret√≥rio de trabalho padr√£o
WORKDIR ${MY_WORKDIR}

# --- C√≥pia dos Bin√°rios e Arquivos da Aplica√ß√£o ---
# Copia os bin√°rios do Hadoop e Spark dos est√°gios de build anteriores
COPY --from=build-hadoop --chown=${MY_USERNAME}:${MY_GROUP} ${HADOOP_HOME} ${HADOOP_HOME}/
COPY --from=build-spark --chown=${MY_USERNAME}:${MY_GROUP} ${SPARK_HOME} ${SPARK_HOME}/

# Copia todos os scripts, templates de configura√ß√£o e outros arquivos necess√°rios.
# O .dockerignore deve ser usado para excluir arquivos desnecess√°rios (ex: .git, README.md).
# O `chown` garante que o usu√°rio da aplica√ß√£o seja o propriet√°rio dos arquivos.
COPY --chown=${MY_USERNAME}:${MY_GROUP} . ${MY_WORKDIR}/

# --- Configura√ß√£o Final do Ambiente do Usu√°rio ---
# Muda para o usu√°rio n√£o-privilegiado para executar comandos que n√£o requerem root
USER ${MY_USERNAME}
RUN \
    # Converte scripts de DOS para UNIX para evitar problemas de formato de linha
    dos2unix -q -k ${MY_WORKDIR}/scripts/*.sh ${MY_WORKDIR}/docker/entrypoint.sh && \
    # Adiciona a fonte do .bash_common ao .bashrc para carregar vari√°veis de ambiente e aliases
    echo -e '\n# Carrega configura√ß√µes comuns do cluster\n[ -f "${HOME}/.bash_common" ] && . "${HOME}/.bash_common"\n' >> "${MY_WORKDIR}/.bashrc" && \
    # Configura SSH para acesso sem senha (necess√°rio para os scripts de gerenciamento do Hadoop)
    ssh-keygen -q -t rsa -N "" -f ${MY_WORKDIR}/.ssh/id_rsa && \
    cat ${MY_WORKDIR}/.ssh/id_rsa.pub >> ${MY_WORKDIR}/.ssh/authorized_keys && \
    # Define permiss√µes restritas para os arquivos SSH
    chmod 0600 ${MY_WORKDIR}/.ssh/authorized_keys ${MY_WORKDIR}/.ssh/config && \
    # Define permiss√µes de execu√ß√£o para os scripts principais
    chmod +x ${MY_WORKDIR}/scripts/*.sh ${MY_WORKDIR}/docker/entrypoint.sh && \
    # Cria o diret√≥rio de log para o Derby (metastore do Spark SQL)
    mkdir -p ${MY_WORKDIR}/derby-metastore

# --- Defini√ß√£o do Entrypoint e Comando Padr√£o ---
# Volta para o usu√°rio root temporariamente para definir o diret√≥rio de trabalho global
USER root
WORKDIR /

# O Entrypoint √© o script que prepara o ambiente em tempo de execu√ß√£o
ENTRYPOINT ["/home/myuser/docker/entrypoint.sh"]

# O Comando padr√£o passado para o Entrypoint.
# Quando um cont√™iner master √© iniciado, ele executar√° `entrypoint.sh bootstrap.sh MASTER`.
# Quando um cont√™iner worker √© iniciado, ele executar√° `entrypoint.sh bootstrap.sh WORKER`.
CMD ["bash", "/home/myuser/scripts/bootstrap.sh", "MASTER"]
